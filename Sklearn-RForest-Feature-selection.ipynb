{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# http://scikit-learn.org/stable/modules/feature_selection.html\n",
      "# http://scikit-learn.org/dev/auto_examples/randomized_search.html#example-randomized-search-py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(__doc__)\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "from time import time\n",
      "from operator import itemgetter\n",
      "from scipy.stats import randint as sp_randint\n",
      "\n",
      "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
      "from sklearn.datasets import load_digits\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "# get some data\n",
      "iris = load_digits()\n",
      "X, y = iris.data, iris.target\n",
      "\n",
      "# build a classifier\n",
      "clf = RandomForestClassifier(n_estimators=50)\n",
      "\n",
      "\n",
      "# Utility function to report best scores\n",
      "def report(grid_scores, n_top=5):\n",
      "    top_scores = sorted(grid_scores, key=itemgetter(1), reverse=True)[:n_top]\n",
      "    for i, score in enumerate(top_scores):\n",
      "        print(\"Model with rank: {0}\".format(i + 1))\n",
      "        print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
      "              score.mean_validation_score,\n",
      "              np.std(score.cv_validation_scores)))\n",
      "        print(\"Parameters: {0}\".format(score.parameters))\n",
      "        print(\"\")\n",
      "\n",
      "\n",
      "# specify parameters and distributions to sample from\n",
      "param_dist = {\"max_depth\": [3, None],\n",
      "              \"max_features\": sp_randint(1, 11),\n",
      "              \"min_samples_split\": sp_randint(1, 11),\n",
      "              \"min_samples_leaf\": sp_randint(1, 11),\n",
      "              \"bootstrap\": [True, False],\n",
      "              \"criterion\": [\"gini\", \"entropy\"]}\n",
      "\n",
      "# run randomized search\n",
      "n_iter_search = 20\n",
      "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
      "                                   n_iter=n_iter_search)\n",
      "\n",
      "start = time()\n",
      "random_search.fit(X, y)\n",
      "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
      "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
      "report(random_search.grid_scores_)\n",
      "\n",
      "# use a full grid over all parameters\n",
      "param_grid = {\"max_depth\": [3, None],\n",
      "              \"max_features\": [1, 3, 10],\n",
      "              \"min_samples_split\": [1, 3, 10],\n",
      "              \"min_samples_leaf\": [1, 3, 10],\n",
      "              \"bootstrap\": [True, False],\n",
      "              \"criterion\": [\"gini\", \"entropy\"]}\n",
      "\n",
      "# run grid search\n",
      "grid_search = GridSearchCV(clf, param_grid=param_grid)\n",
      "start = time()\n",
      "grid_search.fit(X, y)\n",
      "\n",
      "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
      "      % (time() - start, len(grid_search.grid_scores_)))\n",
      "report(grid_search.grid_scores_)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Automatically created module for IPython interactive environment\n",
        "RandomizedSearchCV took 12.76 seconds for 20 candidates parameter settings."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Model with rank: 1\n",
        "Mean validation score: 0.974 (std: 0.002)\n",
        "Parameters: {'bootstrap': False, 'min_samples_leaf': 3, 'min_samples_split': 3, 'criterion': 'gini', 'max_features': 3, 'max_depth': None}\n",
        "\n",
        "Model with rank: 2\n",
        "Mean validation score: 0.973 (std: 0.002)\n",
        "Parameters: {'bootstrap': False, 'min_samples_leaf': 1, 'min_samples_split': 5, 'criterion': 'gini', 'max_features': 2, 'max_depth': None}\n",
        "\n",
        "Model with rank: 3\n",
        "Mean validation score: 0.970 (std: 0.005)\n",
        "Parameters: {'bootstrap': True, 'min_samples_leaf': 2, 'min_samples_split': 1, 'criterion': 'entropy', 'max_features': 8, 'max_depth': None}\n",
        "\n",
        "Model with rank: 4\n",
        "Mean validation score: 0.967 (std: 0.004)\n",
        "Parameters: {'bootstrap': False, 'min_samples_leaf': 5, 'min_samples_split': 8, 'criterion': 'entropy', 'max_features': 3, 'max_depth': None}\n",
        "\n",
        "Model with rank: 5\n",
        "Mean validation score: 0.962 (std: 0.005)\n",
        "Parameters: {'bootstrap': False, 'min_samples_leaf': 8, 'min_samples_split': 5, 'criterion': 'gini', 'max_features': 5, 'max_depth': None}\n",
        "\n",
        "GridSearchCV took 105.05 seconds for 216 candidate parameter settings."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Model with rank: 1\n",
        "Mean validation score: 0.977 (std: 0.006)\n",
        "Parameters: {'bootstrap': False, 'min_samples_leaf': 1, 'min_samples_split': 1, 'criterion': 'entropy', 'max_features': 3, 'max_depth': None}\n",
        "\n",
        "Model with rank: 2\n",
        "Mean validation score: 0.976 (std: 0.003)\n",
        "Parameters: {'bootstrap': True, 'min_samples_leaf': 1, 'min_samples_split': 1, 'criterion': 'entropy', 'max_features': 10, 'max_depth': None}\n",
        "\n",
        "Model with rank: 3\n",
        "Mean validation score: 0.976 (std: 0.005)\n",
        "Parameters: {'bootstrap': False, 'min_samples_leaf': 1, 'min_samples_split': 1, 'criterion': 'gini', 'max_features': 10, 'max_depth': None}\n",
        "\n",
        "Model with rank: 4\n",
        "Mean validation score: 0.976 (std: 0.005)\n",
        "Parameters: {'bootstrap': False, 'min_samples_leaf': 1, 'min_samples_split': 3, 'criterion': 'entropy', 'max_features': 10, 'max_depth': None}\n",
        "\n",
        "Model with rank: 5\n",
        "Mean validation score: 0.976 (std: 0.008)\n",
        "Parameters: {'bootstrap': False, 'min_samples_leaf': 3, 'min_samples_split': 3, 'criterion': 'entropy', 'max_features': 10, 'max_depth': None}\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}